{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Custom Annotations\n",
    "\n",
    "In this notebook, we illustrate how to load an annotations file from one of the *Digital Humanities Datasets* (i.e., artistical or archeological data) so as to fit them into the COCO API.\n",
    "\n",
    "In addition to the code examples, we also give an overview of the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import copy\n",
    "import json \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from resources_angel.utils import print_pairs\n",
    "from resources_angel.detection_coco_eval import CocoEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = np.version.version  # important to work with numpy 1.17 or below\n",
    "assert int(version.split(\".\")[1]) < 18, \"Downgrade your numpy to 1.17 or below\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "JSON_FILE_NAME = \"efi_arthist_valid.json\"\n",
    "JSON_PATH = os.path.join(os.getcwd(), \"resources_coco\", JSON_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Inspection\n",
    "\n",
    "In this section, we load the *JSON* file with the preprocessed (CSV to JSON) annotations and display some stats and a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading annotations\n",
    "with open(JSON_PATH) as file:\n",
    "    annotations = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = annotations[\"annotations\"]\n",
    "n_instances = len(instances)\n",
    "\n",
    "classes = [(ann[\"id\"],ann[\"name\"]) for ann in annotations[\"categories\"]]\n",
    "n_classes = len(classes)\n",
    "\n",
    "imgs = [(img[\"id\"],img[\"file_name\"]) for img in annotations[\"images\"]]\n",
    "n_imgs = len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "---------\n",
      "   Total on 21 classes:\n",
      "      1:putto  2:column  3:mary  4:book  5:gabriel  6:flower  7:bookrest  8:god  9:annunciation  \n",
      "      10:speech scroll  11:basket  12:dove  13:angel  14:scepter  15:flower vase  16:bed  17:stool  \n",
      "      18:jesus child  19:cat  20:vase  21:window  \n",
      "\n",
      "Images: \n",
      "-------\n",
      "Total of 2543 images\n",
      "      0:/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/Joconde/Joconde_iid0103193-000.jpg  \n",
      "      1:/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/RMN/page_3_item_21_09-503957.jpg  \n",
      "      2:/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/stadel/44_initial-m-ornament-mit-verkuendigung-an-maria.jpg  \n",
      "      \n",
      "\n",
      "Annotations: \n",
      "------------\n",
      "Total of 5018 person instances annotated\n",
      "   {'id': 0, 'image_id': 0, 'img_name': 'Joconde_iid0103193-000.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/Joconde/Joconde_iid0103193-000.jpg', 'bbox': '312,205,477,470', 'category_id': 1, 'iscrowd': 0, 'area': 43725}\n",
      "   {'id': 1, 'image_id': 1, 'img_name': 'page_3_item_21_09-503957.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/RMN/page_3_item_21_09-503957.jpg', 'bbox': '0,72,57,568', 'category_id': 2, 'iscrowd': 0, 'area': 28272}\n",
      "   {'id': 2, 'image_id': 2, 'img_name': '44_initial-m-ornament-mit-verkuendigung-an-maria.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/stadel/44_initial-m-ornament-mit-verkuendigung-an-maria.jpg', 'bbox': '455,224,517,323', 'category_id': 3, 'iscrowd': 0, 'area': 6138}\n",
      "   {'id': 3, 'image_id': 3, 'img_name': 'Joconde_ii0000437.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/Joconde/Joconde_ii0000437.jpg', 'bbox': '2,285,66,311', 'category_id': 4, 'iscrowd': 0, 'area': 1664}\n",
      "   {'id': 4, 'image_id': 4, 'img_name': '298339.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/Cini/298339.jpg', 'bbox': '343,275,439,470', 'category_id': 5, 'iscrowd': 0, 'area': 18720}\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes: \")\n",
    "print(\"---------\")\n",
    "print(f\"   Total on {n_classes} classes:\")\n",
    "print_pairs(classes)\n",
    "\n",
    "print(\"\\n\\nImages: \")\n",
    "print(\"-------\")\n",
    "print(f\"Total of {n_imgs} images\")\n",
    "print_pairs(imgs[:3], n_pairs=1)\n",
    "\n",
    "print(\"\\n\\nAnnotations: \")\n",
    "print(\"------------\")\n",
    "print(f\"Total of {n_instances} person instances annotated\")\n",
    "for i in range(5):\n",
    "    print(f\"   {instances[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we need three different fields in the *annotations* json. The script **aux_process_arch_data.py** automatically extracts those from the original *.csv* annotation files:\n",
    " - **images**: Maps the unique ID of a dataset sample (*image_id*) to the name or path of the image used for loading.\n",
    " \n",
    " - **categories**: Maps the numeric identifier of a class with its semantic label (e.g., 1: 'abduction')\n",
    " \n",
    " - **annotations**: Dictionary with the detection information for each of the annotated instances in the dataset. It must containg the following fields:\n",
    "     - **id**: Unique identifier of the detection instance\n",
    "     - **image_id**: Identifier of the image to which the current instance belongs to\n",
    "     - **bbox**: coordinates of the bounding box containing the detection. Format is (x_min, y_min, x_max, y_max)\n",
    "     - **category_id**: numeric identifier of the class to which the detection corresponds\n",
    "     - **iscrowd**: If 1, detection is considered as part of a crowd and results do not count. It is hardcoded to 0 for our data.\n",
    "     - **area**: Area (in pixels) of the bounding box. COCO discards annotatios with areas too large and too small\n",
    "     - **img_name** & **filename**: These are not necessary, but I add them for completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "COCO wants the bounding boxes in the format (x_min, y_min, width, height). Therefore, we need to convert the annotations into the desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_instances = annotations[\"annotations\"]\n",
    "n_instances = len(processed_instances)\n",
    "\n",
    "for inst in processed_instances:\n",
    "    xmin, ymin, xmax, ymax = [int(c) for c in inst[\"bbox\"].split(\",\")]\n",
    "    coords = [xmin, ymin, xmax - xmin, ymax - ymin]  # converting to x,y,w,h\n",
    "    inst[\"bbox\"] = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotations: \n",
      "------------\n",
      "Total of 5018 person instances annotated\n",
      "   {'id': 0, 'image_id': 0, 'img_name': 'Joconde_iid0103193-000.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/Joconde/Joconde_iid0103193-000.jpg', 'bbox': [312, 205, 165, 265], 'category_id': 1, 'iscrowd': 0, 'area': 43725}\n",
      "   {'id': 1, 'image_id': 1, 'img_name': 'page_3_item_21_09-503957.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/RMN/page_3_item_21_09-503957.jpg', 'bbox': [0, 72, 57, 496], 'category_id': 2, 'iscrowd': 0, 'area': 28272}\n",
      "   {'id': 2, 'image_id': 2, 'img_name': '44_initial-m-ornament-mit-verkuendigung-an-maria.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Art_history/latest/stadel/44_initial-m-ornament-mit-verkuendigung-an-maria.jpg', 'bbox': [455, 224, 62, 99], 'category_id': 3, 'iscrowd': 0, 'area': 6138}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nAnnotations: \")\n",
    "print(\"------------\")\n",
    "print(f\"Total of {n_instances} person instances annotated\")\n",
    "for i in range(3):\n",
    "    print(f\"   {processed_instances[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_annotations = {\n",
    "    \"annotations\": processed_instances,\n",
    "    \"images\": annotations[\"images\"],\n",
    "    \"categories\": annotations[\"categories\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'name': 'putto'}, {'id': 2, 'name': 'mary'}, {'id': 3, 'name': 'gabriel'}, {'id': 4, 'name': 'book'}, {'id': 5, 'name': 'column'}, {'id': 6, 'name': 'dove'}, {'id': 7, 'name': 'bookrest'}, {'id': 8, 'name': 'flower'}, {'id': 9, 'name': 'angel'}, {'id': 10, 'name': 'annunciation'}, {'id': 11, 'name': 'flower vase'}, {'id': 12, 'name': 'speech scroll'}, {'id': 13, 'name': 'god'}, {'id': 14, 'name': 'scepter'}, {'id': 15, 'name': 'bed'}, {'id': 16, 'name': 'basket'}, {'id': 17, 'name': 'stool'}, {'id': 18, 'name': 'vase'}, {'id': 19, 'name': 'jesus child'}, {'id': 20, 'name': 'cat'}, {'id': 21, 'name': 'window'}, {'id': 22, 'name': 'door'}]\n"
     ]
    }
   ],
   "source": [
    "annotations[\"categories\"]\n",
    "\n",
    "import yaml\n",
    "params = yaml.safe_load(open(f'projects/efi_arthist.yml'))\n",
    "train_categories = params['obj_list']\n",
    "train_cat_list = []\n",
    "for i, val in enumerate(train_categories):\n",
    "    one_dict = {}\n",
    "    one_dict['id'] = i + 1\n",
    "    one_dict['name'] = val\n",
    "    train_cat_list.append(one_dict)\n",
    "print (train_cat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fitting COCO API\n",
    "\n",
    "We now use the loaded annotations to fit the COCO API and a COCO Evaluator for further evaluation of the detected results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# intiializing COCO dataset and fitting the annotations\n",
    "coco_dataset = COCO()\n",
    "coco_dataset.dataset = fit_annotations\n",
    "coco_dataset.createIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pycocotools.coco.COCO at 0x7f78ee9f1dd8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is necessary to let COCO know that we only do BBOX detection, but not keypoint or mask\n",
    "iou_types = [\"bbox\"]\n",
    "# intializing COCO evaluator\n",
    "coco_evaluator = CocoEvaluator(coco_dataset, iou_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulating Evaluation\n",
    "\n",
    "To make sure everything works alright, we simulate the evaluation process. For simplicity, we use the annotations (instead of the outputs of a CNN) for the evaluation, thus obtaining 100% mAP.\n",
    "\n",
    "Somehow, we only obtain 96.8% mAP. I have not found out yet why this happens, but I conjecture it might be due to rounding issues or to some annotation that is filtered because it does not fulfill the area condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading annotations\n",
    "with open(JSON_PATH) as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "# iterating all images\n",
    "for i, img in enumerate(annotations[\"images\"]):\n",
    "    img_id = img[\"id\"]\n",
    "    boxes, scores, labels = [], [], []\n",
    "    \n",
    "    # obtaining all annotations with the current image id\n",
    "    for j, instance in enumerate(annotations[\"annotations\"]):\n",
    "        inst_id = int(instance[\"image_id\"])\n",
    "        if(inst_id != img_id):\n",
    "            continue\n",
    "        # saving relevant features of current instance\n",
    "        boxes.append([int(coord) for coord in instance[\"bbox\"].split(\",\")])  # coords are string when reading from file\n",
    "        labels.append(instance[\"category_id\"])\n",
    "        scores.append(1)\n",
    "    \n",
    "    # the results must be given in this shape to the COCO Evaluator\n",
    "    output = {\n",
    "        \"scores\": torch.Tensor(scores),\n",
    "        \"labels\": torch.Tensor(labels),\n",
    "        \"boxes\": torch.Tensor(boxes)\n",
    "    }\n",
    "    res = {img_id: output}\n",
    "    # updating the evaluator with current results\n",
    "    coco_evaluator.update(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=0.21s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.952\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.952\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.947\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.944\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.952\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.952\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.947\n"
     ]
    }
   ],
   "source": [
    "coco_evaluator.synchronize_between_processes()\n",
    "coco_evaluator.accumulate()\n",
    "valid_stats = coco_evaluator.summarize()[\"bbox\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycocotools.coco.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=alert style=\"background-color:#F5F5F5; border-color:#C8C8C8\">\n",
    "   This notebook was created by <b>Angel Villar-Corrales</b>\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
