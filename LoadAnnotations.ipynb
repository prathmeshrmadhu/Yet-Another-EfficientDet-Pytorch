{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Custom Annotations\n",
    "\n",
    "In this notebook, we illustrate how to load an annotations file from one of the *Digital Humanities Datasets* (i.e., artistical or archeological data) so as to fit them into the COCO API.\n",
    "\n",
    "In addition to the code examples, we also give an overview of the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import copy\n",
    "import json \n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "from resources_angel.utils import print_pairs\n",
    "from resources_angel.detection_coco_eval import CocoEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = np.version.version  # important to work with numpy 1.17 or below\n",
    "assert int(version.split(\".\")[1]) < 18, \"Downgrade your numpy to 1.17 or below\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "JSON_FILE_NAME = \"efi_classarch_train.json\"\n",
    "JSON_PATH = os.path.join(os.getcwd(), \"resources_coco\", JSON_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Inspection\n",
    "\n",
    "In this section, we load the *JSON* file with the preprocessed (CSV to JSON) annotations and display some stats and a subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading annotations\n",
    "with open(JSON_PATH) as file:\n",
    "    annotations = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = annotations[\"annotations\"]\n",
    "n_instances = len(instances)\n",
    "\n",
    "classes = [(ann[\"id\"],ann[\"name\"]) for ann in annotations[\"categories\"]]\n",
    "n_classes = len(classes)\n",
    "\n",
    "imgs = [(img[\"id\"],img[\"file_name\"]) for img in annotations[\"images\"]]\n",
    "n_imgs = len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: \n",
      "---------\n",
      "   Total on 68 classes:\n",
      "      7:shield  2:spear  15:vessel  17:trident  3:wreath (worn)  1:palmette  24:torch  28:aulos  13:winged sandal  \n",
      "      5:lyre  4:column  16:club  14:Eros  19:kerykeion  30:fish  22:petasos  6:dolphin  \n",
      "      20:quiver  18:thyrsos  38:dog  29:phiale  23:scepter  46:kantharos  10:bow  40:vessel (oinochoe)  \n",
      "      63:vessel (loutrophoros)  9:vessel (kantharos)  11:sword  27:lions skin (headdress)  21:stick  34:door  31:wreath  8:altar  \n",
      "      12:cock  41:hoop  44:tauros  35:centaur  49:hippocamp  37:stephane (bride)  48:pomegranate  26:arrow  \n",
      "      25:tripod  45:phrygian cap  33:cornucopia  59:harp  43:owl  57:panther  32:lion  36:sphinx  \n",
      "      39:thunderbolt  68:harpe  56:ship  67:winged sandals  53:axe  51:box  52:lions skin  47:thymiaterion  \n",
      "      50:basket  55:pom  61:octopus  42:vessel (amphora)  60:ram  54:chimaira  58:pegasus  64:bed  \n",
      "      62:griffin  66:taenia  65:hand-held fan  \n",
      "\n",
      "Images: \n",
      "-------\n",
      "Total of 8636 images\n",
      "      0:/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Herakles/herakles_1010.jpg  \n",
      "      1:/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Dolphin/dolphin_0065.jpg  \n",
      "      2:/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Kantharos/kantharos_1348.jpg  \n",
      "      \n",
      "\n",
      "Annotations: \n",
      "------------\n",
      "Total of 22510 person instances annotated\n",
      "   {'id': 0, 'image_id': 0, 'img_name': 'herakles_1010.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Herakles/herakles_1010.jpg', 'bbox': '326,143,477,339', 'category_id': 7, 'iscrowd': 0, 'area': 29596}\n",
      "   {'id': 1, 'image_id': 1, 'img_name': 'dolphin_0065.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Dolphin/dolphin_0065.jpg', 'bbox': '188,114,273,184', 'category_id': 2, 'iscrowd': 0, 'area': 5950}\n",
      "   {'id': 2, 'image_id': 2, 'img_name': 'kantharos_1348.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Kantharos/kantharos_1348.jpg', 'bbox': '394,9,509,104', 'category_id': 7, 'iscrowd': 0, 'area': 10925}\n",
      "   {'id': 3, 'image_id': 3, 'img_name': 'kantharos_1295.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Kantharos/kantharos_1295.jpg', 'bbox': '281,104,365,180', 'category_id': 15, 'iscrowd': 0, 'area': 6384}\n",
      "   {'id': 4, 'image_id': 4, 'img_name': 'MZKA1274260532.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Trident/MZKA1274260532.jpg', 'bbox': '1490,227,1994,1268', 'category_id': 17, 'iscrowd': 0, 'area': 524664}\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes: \")\n",
    "print(\"---------\")\n",
    "print(f\"   Total on {n_classes} classes:\")\n",
    "print_pairs(classes)\n",
    "\n",
    "print(\"\\n\\nImages: \")\n",
    "print(\"-------\")\n",
    "print(f\"Total of {n_imgs} images\")\n",
    "print_pairs(imgs[:3], n_pairs=1)\n",
    "\n",
    "print(\"\\n\\nAnnotations: \")\n",
    "print(\"------------\")\n",
    "print(f\"Total of {n_instances} person instances annotated\")\n",
    "for i in range(5):\n",
    "    print(f\"   {instances[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we need three different fields in the *annotations* json. The script **aux_process_arch_data.py** automatically extracts those from the original *.csv* annotation files:\n",
    " - **images**: Maps the unique ID of a dataset sample (*image_id*) to the name or path of the image used for loading.\n",
    " \n",
    " - **categories**: Maps the numeric identifier of a class with its semantic label (e.g., 1: 'abduction')\n",
    " \n",
    " - **annotations**: Dictionary with the detection information for each of the annotated instances in the dataset. It must containg the following fields:\n",
    "     - **id**: Unique identifier of the detection instance\n",
    "     - **image_id**: Identifier of the image to which the current instance belongs to\n",
    "     - **bbox**: coordinates of the bounding box containing the detection. Format is (x_min, y_min, x_max, y_max)\n",
    "     - **category_id**: numeric identifier of the class to which the detection corresponds\n",
    "     - **iscrowd**: If 1, detection is considered as part of a crowd and results do not count. It is hardcoded to 0 for our data.\n",
    "     - **area**: Area (in pixels) of the bounding box. COCO discards annotatios with areas too large and too small\n",
    "     - **img_name** & **filename**: These are not necessary, but I add them for completeness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "COCO wants the bounding boxes in the format (x_min, y_min, width, height). Therefore, we need to convert the annotations into the desired format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_instances = annotations[\"annotations\"]\n",
    "n_instances = len(processed_instances)\n",
    "\n",
    "for inst in processed_instances:\n",
    "    xmin, ymin, xmax, ymax = [int(c) for c in inst[\"bbox\"].split(\",\")]\n",
    "    coords = [xmin, ymin, xmax - xmin, ymax - ymin]  # converting to x,y,w,h\n",
    "    inst[\"bbox\"] = coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Annotations: \n",
      "------------\n",
      "Total of 22510 person instances annotated\n",
      "   {'id': 0, 'image_id': 0, 'img_name': 'herakles_1010.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Herakles/herakles_1010.jpg', 'bbox': [326, 143, 151, 196], 'category_id': 7, 'iscrowd': 0, 'area': 29596}\n",
      "   {'id': 1, 'image_id': 1, 'img_name': 'dolphin_0065.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Dolphin/dolphin_0065.jpg', 'bbox': [188, 114, 85, 70], 'category_id': 2, 'iscrowd': 0, 'area': 5950}\n",
      "   {'id': 2, 'image_id': 2, 'img_name': 'kantharos_1348.jpg', 'filename': '/localhome/prathmeshmadhu/work/EFI/Data/Classical_Arch/latest/Kantharos/kantharos_1348.jpg', 'bbox': [394, 9, 115, 95], 'category_id': 7, 'iscrowd': 0, 'area': 10925}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nAnnotations: \")\n",
    "print(\"------------\")\n",
    "print(f\"Total of {n_instances} person instances annotated\")\n",
    "for i in range(3):\n",
    "    print(f\"   {processed_instances[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_annotations = {\n",
    "    \"annotations\": processed_instances,\n",
    "    \"images\": annotations[\"images\"],\n",
    "    \"categories\": annotations[\"categories\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fitting COCO API\n",
    "\n",
    "We now use the loaded annotations to fit the COCO API and a COCO Evaluator for further evaluation of the detected results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# intiializing COCO dataset and fitting the annotations\n",
    "coco_dataset = COCO()\n",
    "coco_dataset.dataset = fit_annotations\n",
    "coco_dataset.createIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is necessary to let COCO know that we only do BBOX detection, but not keypoint or mask\n",
    "iou_types = [\"bbox\"]\n",
    "# intializing COCO evaluator\n",
    "coco_evaluator = CocoEvaluator(coco_dataset, iou_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simulating Evaluation\n",
    "\n",
    "To make sure everything works alright, we simulate the evaluation process. For simplicity, we use the annotations (instead of the outputs of a CNN) for the evaluation, thus obtaining 100% mAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading annotations\n",
    "with open(JSON_PATH) as file:\n",
    "    annotations = json.load(file)\n",
    "\n",
    "# iterating all images\n",
    "for i, img in enumerate(annotations[\"images\"]):\n",
    "    img_id = img[\"id\"]\n",
    "    boxes, scores, labels = [], [], []\n",
    "    \n",
    "    # obtaining all annotations with the current image id\n",
    "    for j, instance in enumerate(annotations[\"annotations\"]):\n",
    "        inst_id = int(instance[\"image_id\"])\n",
    "        if(inst_id != img_id):\n",
    "            continue\n",
    "        # saving relevant features of current instance\n",
    "        boxes.append([int(coord) for coord in instance[\"bbox\"].split(\",\")])  # coords are string when reading from file\n",
    "        labels.append(instance[\"category_id\"])\n",
    "        scores.append(1)\n",
    "    \n",
    "    # the results must be given in this shape to the COCO Evaluator\n",
    "    output = {\n",
    "        \"scores\": torch.Tensor(scores),\n",
    "        \"labels\": torch.Tensor(labels),\n",
    "        \"boxes\": torch.Tensor(boxes)\n",
    "    }\n",
    "    res = {img_id: output}\n",
    "    # updating the evaluator with current results\n",
    "    coco_evaluator.update(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating evaluation results...\n",
      "DONE (t=2.33s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.853\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.999\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 1.000\n"
     ]
    }
   ],
   "source": [
    "coco_evaluator.synchronize_between_processes()\n",
    "coco_evaluator.accumulate()\n",
    "valid_stats = coco_evaluator.summarize()[\"bbox\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=alert style=\"background-color:#F5F5F5; border-color:#C8C8C8\">\n",
    "   This notebook was created by <b>Angel Villar-Corrales</b>\n",
    "</div> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
